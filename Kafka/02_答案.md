# Kafka面试题答案

## 1. Kafka架构和核心概念？

**题目：**
Kafka的架构是什么样的？有哪些核心概念？

**答案：**
**Kafka架构：**
```
┌─────────────────────────────────────────────────────────────┐
│                       Kafka Cluster                         │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐        │
│  │  Broker 1   │  │  Broker 2   │  │  Broker 3   │        │
│  │  Topic-A    │  │  Topic-A    │  │  Topic-A    │        │
│  │  Part-0,1   │  │  Part-2,3   │  │  Part-4,5   │        │
│  └─────────────┘  └─────────────┘  └─────────────┘        │
│                        ↑                                   │
│  ┌─────────────────────────────────────────────────────┐   │
│  │                   Zookeeper                          │   │
│  │   - Broker注册  - Topic配置  - Leader选举            │   │
│  └─────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────┘
```

**核心概念：**

| 概念 | 说明 |
|------|------|
| **Broker** | Kafka服务器节点 |
| **Topic** | 消息主题 |
| **Partition** | 分区，物理分组 |
| **Replica** | 分区副本 |
| **Producer** | 生产者 |
| **Consumer** | 消费者 |
| **Consumer Group** | 消费者组 |
| **Offset** | 消费位移 |

**分区与副本：**
```
Topic: Order
├── Partition 0 (Leader: Broker 1, Replica: Broker 1,2)
├── Partition 1 (Leader: Broker 2, Replica: Broker 2,3)
└── Partition 2 (Leader: Broker 3, Replica: Broker 3,1)
```

**数据存储：**
```
Partition → Segments (.log) → Index (.index)
```

---

## 2. Kafka消息顺序性保证？

**题目：**
Kafka如何保证消息顺序性？

**答案：**
**Kafka顺序性保证：**

**1. 单分区有序**
```
同一Partition内的消息有序
不同Partition间无序
```

**2. 全局有序实现**
```
方案：单分区
- 一个Topic只有一个Partition
- 缺点：吞吐量低
```

**3. 局部有序实现（常用）**
```
方案：按Key路由
- 相同Key的消息发送到同一Partition
- 满足业务有序性（如同一订单的消息）

示例：
producer.send(new ProducerRecord<>(topic, orderId, message));
```

**生产者配置：**
```java
// 按Key路由
Properties props = new Properties();
props.put("bootstrap.servers", "localhost:9092");
props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");

// 保证消息有序
props.put("max.in.flight.requests.per.connection", 1);
```

**消费者配置：**
```java
// 单线程消费
properties.put("group.instance.id", "consumer-1");
```

---

## 3. Kafka如何保证消息不丢失？

**题目：**
Kafka如何保证消息不丢失？

**答案：**
**消息丢失场景：**

**1. 生产者丢失**
```java
// 配置
props.put("acks", "all");        // 确认机制
props.put("retries", 3);          // 重试次数
props.put("enable.idempotence", true);  // 幂等性
```

**acks配置：**
| 值 | 说明 | 安全性 |
|---|------|--------|
| 0 | 不确认 | ❌ 可能丢失 |
| 1 | Leader确认 | ⚠️ 可能丢失 |
| all | ISR确认 | ✅ 最安全 |

**2. Broker丢失**
```bash
# 配置副本
default.replication.factor=3

# ISR配置
min.insync.replicas=2

# 防止丢数据
unclean.leader.election.enable=false
```

**3. 消费者丢失**
```java
// 手动提交offset
consumer.commitSync();  // 同步提交

// 或先处理再提交
while (true) {
    ConsumerRecords<String, String> records = consumer.poll(100);
    for (ConsumerRecord<String, String> record : records) {
        process(record);  // 先处理
    }
    consumer.commitSync();  // 再提交
}
```

**最佳实践：**
```
生产者：acks=all + retries=3 + idempotence=true
Broker：replication.factor=3 + min.insync.replicas=2
消费者：手动提交offset
```

---

## 4. Kafka如何保证消息不重复消费？

**题目：**
Kafka如何避免消息重复消费？

**答案：**
**消息重复原因：**
- 生产者重试导致重复发送
- 消费者再均衡导致重复消费
- 手动提交offset失败

**解决方案：**

**1. 生产者幂等性**
```java
props.put("enable.idempotence", true);
// 自动去重
```

**2. 消费者幂等性**
```java
// 业务去重
Map<String, Boolean> processed = new ConcurrentHashMap<>();

for (ConsumerRecord<String, String> record : records) {
    String key = record.key();
    if (processed.containsKey(key)) {
        continue;  // 跳过已处理
    }
    process(record);
    processed.put(key, true);
}
```

**3. 数据库唯一约束**
```sql
-- 订单表添加唯一索引
CREATE TABLE order (
    order_id VARCHAR(32) PRIMARY KEY,
    ...
);

-- 重复插入会报错
INSERT INTO order (...) VALUES (...) 
ON DUPLICATE KEY UPDATE status = 'PAID';
```

**4. 分布式锁**
```java
String lockKey = "process:" + orderId;
boolean locked = redisTemplate.opsForValue()
    .setIfAbsent(lockKey, "1", 10, TimeUnit.SECONDS);

if (locked) {
    try {
        processOrder(orderId);
    } finally {
        redisTemplate.delete(lockKey);
    }
}
```

**消费语义：**
```
At most once：最多一次（可能丢失）
At least once：至少一次（可能重复）← Kafka默认
Exactly once：精确一次（需配置）
```

---

## 5. Kafka分区策略？

**题目：**
Kafka有哪些分区策略？

**答案：**
**生产者分区策略：**

**1. 轮询策略（默认）**
```java
// 按顺序分配到不同Partition
// 负载均衡
```

**2. 随机策略**
```java
// 随机选择一个Partition
props.put("partitioner.class", 
    "org.apache.kafka.clients.producer.RoundRobinPartitioner");
```

**3. 按Key哈希策略（默认）**
```java
// 根据Key的hash值分配
// 相同Key到同一Partition
props.put("partitioner.class", 
    "org.apache.kafka.common.serialization.StringPartitioner");
```

**4. 自定义策略**
```java
public class MyPartitioner implements Partitioner {
    
    public int partition(String topic, Object key, 
                        byte[] keyBytes, 
                        Object value, 
                        byte[] valueBytes,
                        Cluster cluster) {
        // 自定义逻辑
        int partitionCount = cluster.partitionsForTopic(topic).size();
        return Math.abs(key.hashCode()) % partitionCount;
    }
}

props.put("partitioner.class", "com.example.MyPartitioner");
```

**消费者分区策略：**
```java
// Range（默认）
// 按消费者顺序分配

// RoundRobin
// 轮询分配
props.put("partition.assignment.strategy", 
    "org.apache.kafka.clients.consumer.RoundRobinAssignor");
```

---

## 6. Kafka消费者组原理？

**题目：**
Kafka消费者组是什么？如何工作？

**答案：**
**消费者组概念：**
```
Consumer Group = 多个消费者实例
同一Group内的消费者共同消费一个Topic
不同Group独立消费（重复消费）
```

**分区分配：**
```
Topic: Order (3个Partition)
Group: consumer-group-1
├── Consumer 1 → Partition 0
├── Consumer 2 → Partition 1
└── Consumer 3 → Partition 2

Group: consumer-group-2
├── Consumer 1 → Partition 0, 1
└── Consumer 2 → Partition 2
```

**再均衡（Rebalance）：**
```
触发时机：
1. 消费者加入/离开
2. 分区数量变化
3. 消费者超时

分配策略：
- Range：按范围分配
- RoundRobin：轮询分配
- StickyAssignor：粘性分配
```

**再均衡过程：**
```
1. 触发再均衡
2. 停止消费
3. 重新分配分区
4. 继续消费
```

**消费者配置：**
```java
props.put("group.id", "my-consumer-group");
props.put("auto.offset.reset", "earliest");  // earliest/latest
props.put("enable.auto.commit", false);       // 手动提交
```

---

## 7. Kafka offsets管理？

**题目：**
Kafka的offset是如何管理的？

**答案：**
**Offset存储位置：**

**1. Kafka（默认，__consumer_offsets）**
```java
// 自动提交offset
props.put("enable.auto.commit", true);
props.put("auto.commit.interval.ms", 5000);
```

**2. Zookeeper（老版本，不推荐）**

**3. 自定义存储**
```java
// 实现ConsumerRebalanceListener
consumer.subscribe(topics, new ConsumerRebalanceListener() {
    
    public void onPartitionsRevoked(Collection<TopicPartition> partitions) {
        // 分区被回收前，保存offset到DB
        saveOffsetToDB(partitions);
    }
    
    public void onPartitionsAssigned(Collection<TopicPartition> partitions) {
        // 分区分配后，从DB恢复offset
        offsets = loadOffsetFromDB(partitions);
        consumer.seek(partitions, offsets);
    }
});
```

**Offset提交时机：**
```
1. 同步提交
consumer.commitSync();

2. 异步提交
consumer.commitAsync((offsets, exception) -> {
    if (exception != null) {
        // 处理异常
    }
});
```

**Offset语义：**
```
Earliest：重头消费
Latest：从最新开始（默认）
Specified：指定位置
```

---

## 8. Kafka高性能原因？

**题目：**
Kafka为什么高性能？

**答案：**
**1. 顺序写磁盘**
```
磁盘顺序写：600MB/s
磁盘随机写：100KB/s

Kafka顺序追加写入
```

**2. 零拷贝**
```
传统：4次拷贝
DMA → 内核缓冲区 → 用户空间 → 套接字缓冲区 → 网卡

Kafka：2次拷贝
DMA → 内核缓冲区 → 网卡
```

**3. 批量处理**
```
Producer：批量发送
Consumer：批量拉取
Broker：批量写入
```

**4. 压缩传输**
```
支持：GZIP, Snappy, LZ4, ZSTD
减少网络传输
```

**5. 分区并行**
```
Topic → 多Partition → 并行消费
```

**6. 高效序列化**
```
Kafka自有序列化框架
高效二进制格式
```

**架构图：**
```
┌─────────────────────────────────────────────────────────┐
│                    Kafka高性能架构                        │
│                                                         │
│  Producer → 批量发送 → 压缩 → 分区 → 顺序写磁盘          │
│                                                         │
│  Broker   → 零拷贝 → 批量读取 → 压缩传输                 │
│                                                         │
│  Consumer → 批量拉取 → 并行消费                         │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

## 9. Kafka与其他消息队列对比？

**题目：**
Kafka、RabbitMQ、RocketMQ对比？

**答案：**
**对比表格：**

| 特性 | Kafka | RabbitMQ | RocketMQ |
|------|-------|----------|----------|
| **吞吐量** | 极高（百万级） | 中等（万级） | 高（十万级） |
| **延迟** | 低 | 低 | 低 |
| **可靠性** | 高 | 高 | 高 |
| **事务** | 支持（事务消息） | 支持（TX） | 支持（事务消息） |
| **顺序消息** | 支持（单分区） | 支持 | 支持 |
| **持久化** | 磁盘 | 内存+磁盘 | 磁盘 |
| **复杂度** | 中 | 高 | 中 |
| **适用场景** | 日志、流处理 | 企业集成 | 电商、金融 |

**选择建议：**
```
日志处理、大数据：Kafka
企业集成、复杂路由：RabbitMQ
电商订单、金融交易：RocketMQ
```

---

## 10. Kafka数据积压处理？

**题目：**
Kafka数据积压怎么办？

**答案：**
**数据积压原因：**
- 消费者处理慢
- 消费者实例不足
- 分区数不合理

**解决方案：**

**1. 增加消费者实例**
```java
// 增加consumer数量
// 最多等于partition数量
```

**2. 增加分区数**
```bash
kafka-topics.sh --alter --topic my-topic --partitions 10
```

**3. 优化消费者性能**
```java
// 批量处理
consumer.poll(1000);

// 异步处理
executor.submit(() -> process(record));
```

**4. 增加批处理大小**
```java
props.put("max.poll.records", 500);
props.put("fetch.max.bytes", 10485760);  // 10MB
```

**5. 并行处理**
```java
ExecutorService executor = Executors.newFixedThreadPool(10);

for (ConsumerRecord<String, String> record : records) {
    executor.submit(() -> process(record));
}
```

**6. 限流**
```java
// 限流消费速度
RateLimiter limiter = RateLimiter.create(1000);
```

**监控：**
```bash
# 查看积压
kafka-consumer-groups.sh --describe --group my-group

# 输出
TOPIC    PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG
topic-0  0          1000            2000            1000
```

---

*更多Kafka面试题答案*
