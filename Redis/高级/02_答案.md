# Redis 高级面试题答案

## 1. Redis 数据结构底层实现？

**题目：**
请详细说明 Redis 常用数据结构的底层实现原理。

**答案：**
**Redis 数据结构总览：**
```
┌─────────────────────────────────────────────────────────────────┐
│                        Redis 数据结构                            │
├─────────────────────────────────────────────────────────────────┤
│  String（字符串）        → SDS（简单动态字符串）                  │
│  List（列表）            → QuickList（快速链表）                  │
│  Hash（哈希）            → ziplist / dict                        │
│  Set（集合）             → intset / dict                         │
│  Sorted Set（有序集合）  → ziplist / skiplist + dict             │
└─────────────────────────────────────────────────────────────────┘
```

**SDS（Simple Dynamic String）：**
```c
// SDS 结构
struct sdshdr {
    int len;       // 已使用字节数
    int free;      // 空闲字节数
    char buf[];    // 字节数组
};

// 特点：
// 1. O(1) 获取字符串长度（不用遍历）
// 2. 防止缓冲区溢出（自动扩容）
// 3. 减少内存分配次数（空间预分配、惰性释放）
// 4. 二进制安全（可以存储二进制数据）

// 扩容策略：
// - 如果 len < 1MB：扩容后 = free + len * 2
// - 如果 len >= 1MB：扩容后 = free + 1MB
```

**QuickList（快速链表）：**
```
┌─────────────────────────────────────────────────────────────┐
│                      QuickList 结构                          │
│                                                              │
│  ┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐     │
│  │ head    │──>│ zlnode  │──>│ zlnode  │──>│ zlnode  │     │
│  │ tail    │   │ (压缩表)│   │ (压缩表)│   │ (压缩表)│     │
│  │ len     │   └─────────┘   └─────────┘   └─────────┘     │
│  │ ...     │                                                │
│  └─────────┘                                                │
│                                                              │
│  每个节点是一个 ziplist：                                    │
│  ┌─────────────────────────────────────┐                    │
│  │ zlbytes │ zltail │ zllen │ entries │ zlend │             │
│  │ 长度    │ 尾偏移  │ 数量   │ 数据项   │ 结束  │             │
│  └─────────────────────────────────────┘                    │
└─────────────────────────────────────────────────────────────┘

// QuickList 特点：
// - 结合了链表和数组的优点
// - 头部和尾部插入 O(1)
// - 内存连续，缓存友好
// - 节点大小可配置（list-compress-depth）
```

**ziplist（压缩列表）：**
```c
// ziplist 结构
struct ziplist {
    uint32_t zlbytes;  // 总字节数
    uint32_t zltail;   // 最后一个元素的偏移量
    uint16_t zllen;    // 元素个数
    element entries[]; // 元素列表
    uint8_t zlend;     // 结束标记 0xFF
}

// entry 结构
struct entry {
    uint32_t prevlen;  // 前一个 entry 长度
    uint32_t encoding; // 编码方式
    byte[] content;    // 内容
}

// 编码方式：
// - 00xxxxxx：字符串，6 位表示长度
// - 01xxxxxx：字符串，14 位表示长度
// - 10xxxxxx：字符串，32 位表示长度
// - 11000000：int16
// - 11000001：int32
// - 11000010：int64
// - 11000011：24 位整数
// - 11001000：int8
```

**intset（整数集合）：**
```c
// intset 结构
struct intset {
    uint32_t encoding;  // 编码方式（16/32/64位）
    uint32_t length;    // 元素个数
    int8_t contents[];  // 元素数组（从小到大排序）
}

// 特点：
// - 元素从小到大排序
// - 支持升级（16 → 32 → 64）
// - 查询使用二分查找 O(log n)
// - 插入/删除需要移动元素 O(n)
```

**skiplist（跳表）：**
```
┌─────────────────────────────────────────────────────────────┐
│                      SkipList 结构                           │
│                                                              │
│  Level 3:  head ──────────────────────────────────────────► │
│                                                              │
│  Level 2:  head ────────────────► ───────────────────────► │
│                                    │                        │
│  Level 1:  head ───────► ───────► ───────► ──────────────►│
│                    │        │        │        │             │
│  Level 0:  head ──►──1───►──2───►──3───►──4───►──5───►   │
│                                                              │
│  查找 4：从最高层开始，跳过 3 到达 4                         │
└─────────────────────────────────────────────────────────────┘

// 跳表节点结构
struct zskiplistNode {
    robj* obj;           // 存储的元素
    double score;        // 分值（用于排序）
    int level;           // 层数
    zskiplistNode* backward;  // 前向指针
    struct {
        zskiplistNode* forward;  // 该层的前向指针
        int span;                // 跨度（用于 rank 计算）
    } level[];
}

// 特点：
// - 平均 O(log n) 查询复杂度
// - 实现比平衡树简单
// - 范围查询友好
// - Redis 使用跳表实现 Sorted Set
```

**dict（字典）：**
```c
// dict 结构
struct dict {
    dictType* type;      // 类型特定函数
    void* privdata;      // 私有数据
    dictht ht[2];        // 两个哈希表（用于 rehash）
    int rehashidx;       // rehash 进度（-1 表示未在进行）
}

// dictht（哈希表）
struct dictht {
    dictEntry** table;   // 哈希表数组
    unsigned long size;  // 表大小
    unsigned long sizemask;  // 掩码 = size - 1
    unsigned long used;  // 已使用元素数
}

// dictEntry（哈希表项）
struct dictEntry {
    void* key;           // 键
    union {
        void* val;
        uint64_t u64;
        int64_t s64;
    } v;
    dictEntry* next;     // 下一个项（链地址法解决冲突）
}

// rehash 过程：
// 1. 为 ht[1] 分配空间（ht[0].used * 2）
// 2. 渐进式 rehash（每次迁移一个桶）
// 3. ht[0] 迁移完成后，交换 ht[0] 和 ht[1]
// 4. 重置 ht[1]，标记 rehashidx = -1
```

---

## 2. Redis 集群选举机制？

**题目：**
请详细说明 Redis 集群的故障检测和选举机制。

**答案：**
**Redis 集群架构：**
```
┌─────────────────────────────────────────────────────────────────┐
│                    Redis Cluster 架构                           │
│                                                              │
│  ┌─────────┐  ┌─────────┐  ┌─────────┐                        │
│  │ Master1 │  │ Master2 │  │ Master3 │  16384 个槽           │
│  │  ( Slot │  │  ( Slot │  │  ( Slot │                        │
│  │   0-5k) │  │ 5k-10k) │  │10k-16k) │                        │
│  └────┬────┘  └────┬────┘  └────┬────┘                        │
│       │            │            │                               │
│  ┌────┴────┐  ┌────┴────┐  ┌────┴────┐                        │
│  │ Slave1  │  │ Slave2  │  │ Slave3  │  自动故障转移           │
│  └─────────┘  └─────────┘  └─────────┘                        │
│                                                              │
│  所有节点通过 Gossip 协议通信                                  │
└─────────────────────────────────────────────────────────────────┘
```

**故障检测：**
```c
// 1. 主观下线（PFail）
//    某个节点认为另一个节点不可用
//    节点定期向其他节点发送 Ping/Pong
//    如果超时未回复，标记为 PFail

// 2. 客观下线（Fail）
//    超过半数主节点认为某个主节点 PFail
//    该主节点被标记为 Fail
//    从节点开始竞选

// 故障检测流程：
void handleNodeTimeout(Node* node) {
    node->fail_time = currentTime();
    
    // 广播 PFail
    broadcastPFail(node);
    
    // 检查是否达到客观下线条件
    if (countPFail(node) > (clusterNodeCount() / 2)) {
        markNodeAsFail(node);  // 客观下线
        notifySlaveElection(node);  // 触发选举
    }
}
```

**从节点选举（Raft 协议变种）：**
```
选举流程：

1. 从节点检测到主节点客观下线
   │
   ▼

2. 从节点延迟一定时间后开始竞选
   延迟时间 = 500ms + random(0, 500ms) * slave_rank
   （rank 越小，延迟越短）
   │
   ▼

3. 向集群中所有主节点发送 MYSLAVEID 消息
   │
   ▼

4. 主节点投票（每个主节点只能投一票）
   - 如果从节点是第一次请求：投票
   - 如果已经投过票：拒绝
   - 投票给请求的第一个从节点
   │
   ▼

5. 从节点收集选票
   - 获得大多数主节点投票 → 成为新主节点
   - 未获得大多数 → 竞选失败，等待下次竞选
   │
   ▼

6. 新主节点开始接收客户端请求
   - 向集群广播 PONG 消息
   - 开始复制旧主节点的数据
```

**选举关键点：**
```c
// 1. 投票机制
int voteForSlave(Slave* slave) {
    // 每个主节点只有一个投票机会
    if (this->voted_slave != null) {
        return 0;  // 已经投过票
    }
    
    // 只投给第一个请求的从节点
    this->voted_slave = slave;
    return 1;
}

// 2. 延迟计算公式
int getElectionDelay(Slave* slave) {
    // rank：表示从节点的数据复制进度
    // rank 越小，说明数据越新
    // delay = 500ms + random(0, 500ms) * 2^rank
    
    if (slave->rank == 0) {
        return 500;  // 最快复制完成的从节点
    }
    
    return 500 + random(0, 500) * (1 << slave->rank);
}

// 3. 竞选条件
int canStartElection(Slave* slave) {
    // 主节点必须客观下线
    if (!masterIsFail(slave->master)) {
        return 0;
    }
    
    // 从节点必须可以连接
    if (!slave->canConnect()) {
        return 0;
    }
    
    // 数据复制进度不能太落后
    if (slave->offset < master->min_slave_offset) {
        return 0;
    }
    
    return 1;
}
```

**新主节点上线：**
```c
void becomeNewMaster(Slave* slave) {
    // 1. 更新集群配置
    clusterSetNodeAsMaster(slave);
    
    // 2. 清除旧的从节点关系
    clusterRemoveSlaveFromMaster(slave->master, slave);
    
    // 3. 广播新主节点信息
    clusterBroadcastPong(slave);
    
    // 4. 开始处理客户端请求
    slave->role = MASTER;
    
    // 5. 将旧主节点设为自己的从节点
    clusterAddSlave(slave, slave->master);
}
```

---

## 3. Redis 分布式锁？

**题目：**
请详细说明 Redis 分布式锁的实现方案及注意事项。

**答案：**
**分布式锁要求：**
```
1. 互斥性：同一时刻只有一个客户端能获取锁
2. 安全性：锁只能被持有者释放
3. 死锁避免：即使持有锁的客户端崩溃，也能释放锁
4. 容错性：只要 Redis 节点存活，客户端就能获取/释放锁
```

**简单实现：**
```java
// 使用 SETNX
public boolean tryLock(String key, String value, long expireTime) {
    Long result = jedis.setnx(key, value);
    if (result == 1) {
        // 设置过期时间
        jedis.expire(key, expireTime);
        return true;
    }
    return false;
}

public void unlock(String key, String value) {
    // 检查是否是持有者
    if (jedis.get(key).equals(value)) {
        jedis.del(key);
    }
}

// 问题：
// 1. setnx 和 expire 不是原子操作（可能死锁）
// 2. 解锁时没有验证持有者（可能误删）
```

**正确实现（原子操作）：**
```java
public class RedisLock {
    
    private Jedis jedis;
    private String lockKey;
    private String lockValue;
    private int expireTime;
    
    public boolean tryLock() {
        // SET key value NX PX expireTime
        String result = jedis.set(lockKey, lockValue, 
            "NX", "PX", expireTime);
        return "OK".equals(result);
    }
    
    public boolean unlock() {
        // 使用 Lua 脚本保证原子性
        String script = 
            "if redis.call('get', KEYS[1]) == ARGV[1] " +
            "then return redis.call('del', KEYS[1]) " +
            "else return 0 end";
            
        Object result = jedis.eval(script, 
            Collections.singletonList(lockKey), 
            Collections.singletonList(lockValue));
            
        return result.equals(1L);
    }
}

// 使用
RedisLock lock = new RedisLock("order_lock", 
    UUID.randomUUID().toString(), 30000);

try {
    if (lock.tryLock()) {
        // 执行业务逻辑
        createOrder();
    }
} finally {
    lock.unlock();
}
```

**RedLock 算法（红锁）：**
```java
// 传统单节点 Redis 锁的问题：
// - 主节点崩溃，从节点未同步锁信息 → 锁丢失

// RedLock 解决方案：
// 向 N 个独立的 Redis 节点获取锁

public class RedLock {
    private List<Jedis> jedisNodes;
    private int quorum;  // 多数 = N/2 + 1
    
    public boolean tryLock(String key, String value, 
            long expireTime) {
        int successCount = 0;
        
        // 向所有节点获取锁
        for (Jedis jedis : jedisNodes) {
            String result = jedis.set(key, value, "NX", "PX", expireTime);
            if ("OK".equals(result)) {
                successCount++;
            }
        }
        
        // 超过半数节点成功
        return successCount >= quorum;
    }
    
    public void unlock(String key, String value) {
        // 向所有节点释放锁
        for (Jedis jedis : jedisNodes) {
            try {
                String script = 
                    "if redis.call('get', KEYS[1]) == ARGV[1] " +
                    "then return redis.call('del', KEYS[1]) " +
                    "else return 0 end";
                jedis.eval(script, 
                    Collections.singletonList(key), 
                    Collections.singletonList(value));
            } catch (Exception e) {
                // 忽略单个节点失败
            }
        }
    }
}
```

**锁续期（WatchDog）：**
```java
// 问题：业务处理时间超过锁过期时间

// 解决方案：锁续期

public class AutoRenewLock {
    
    private static final long RENEW_INTERVAL = 10000;  // 10秒
    private static final long EXPIRE_TIME = 30000;     // 30秒
    
    private volatile boolean isRunning = true;
    private Thread renewThread;
    
    public void tryLockWithRenew(String key, String value) {
        // 获取锁
        boolean locked = jedis.set(key, value, "NX", "PX", EXPIRE_TIME)
            .equals("OK");
        
        if (!locked) {
            throw new LockException("获取锁失败");
        }
        
        // 启动续期线程
        renewThread = new Thread(() -> {
            while (isRunning) {
                try {
                    Thread.sleep(RENEW_INTERVAL);
                    
                    // 检查锁是否还存在
                    String currentValue = jedis.get(key);
                    if (value.equals(currentValue)) {
                        // 续期
                        jedis.expire(key, EXPIRE_TIME);
                    } else {
                        // 锁已释放，退出
                        break;
                    }
                } catch (Exception e) {
                    break;
                }
            }
        });
        renewThread.start();
    }
    
    public void unlock(String key, String value) {
        isRunning = false;
        
        // 释放锁
        String script = 
            "if redis.call('get', KEYS[1]) == ARGV[1] " +
            "then return redis.call('del', KEYS[1]) " +
            "else return 0 end";
        jedis.eval(script, 
            Collections.singletonList(key), 
            Collections.singletonList(value));
    }
}
```

---

## 4. Redis 内存淘汰策略？

**题目：**
Redis 有哪些内存淘汰策略？分别适用于什么场景？

**答案：**
**内存淘汰策略分类：**
```
┌─────────────────────────────────────────────────────────────┐
│                  Redis 内存淘汰策略                          │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  ┌────────────────────┐    ┌────────────────────┐          │
│  │   noeviction       │    │  volatile-*        │          │
│  │   （不淘汰）        │    │  （过期键淘汰）     │          │
│  └────────────────────┘    └────────────────────┘          │
│                                                              │
│  ┌────────────────────┐    ┌────────────────────┐          │
│  │   allkeys-*        │    │  volatile-ttl      │          │
│  │  （所有键淘汰）     │    │  （过期时间优先）   │          │
│  └────────────────────┘    └────────────────────┘          │
│                                                              │
│  淘汰算法：                                                   │
│  - LRU（Least Recently Used）                                │
│  - LFU（Least Frequently Used）                              │
│  - Random（随机）                                            │
│  - TTL（过期时间）                                           │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

**八种策略详解：**
```sql
-- 1. noeviction（默认）
-- 不淘汰任何数据，内存满时返回错误
-- 适用：对数据敏感，不能丢失任何数据

-- 2. volatile-ttl
-- 从过期键中淘汰 TTL 最短的
-- 适用：可以区分过期时间的场景

-- 3. volatile-random
-- 从过期键中随机淘汰
-- 适用：过期时间分布均匀的场景

-- 4. volatile-lru
-- 从过期键中淘汰最近最少使用的
-- 适用：热点数据不会过期的场景

-- 5. volatile-lfu
-- 从过期键中淘汰使用频率最低的
-- 适用：访问频率有明确差异的场景

-- 6. allkeys-random
-- 从所有键中随机淘汰
-- 适用：所有数据都可以被淘汰

-- 7. allkeys-lru
-- 从所有键中淘汰最近最少使用的
-- 适用：热点数据有明显冷热区分

-- 8. allkeys-lfu
-- 从所有键中淘汰使用频率最低的
-- 适用：访问频率有明确区分的场景
```

**配置方式：**
```bash
# Redis 配置文件
maxmemory 2gb                    # 最大内存
maxmemory-policy allkeys-lru     # 淘汰策略
maxmemory-samples 5              # LRU/LFU 采样数
```

**LRU 算法实现：**
```c
// Redis LRU 实现（近似算法）
// 不是真正的 LRU，而是采样后选择最大的

struct redisObject {
    unsigned type:4;
    unsigned encoding:4;
    unsigned lru:24;  // LRU 时钟
    int refcount;
    void* ptr;
};

// LRU 时钟（单位：秒）
#define REDIS_LRU_CLOCK_MAX ((1<<24)-1)
#define REDIS_LRU_CLOCK_RESOLUTION 1  // 1秒

// 获取对象的 LRU 值
int estimateObjectIdleTime(robj* o) {
    unsigned long now = getLRUClock();
    unsigned long idle = now - o->lru;
    
    // 转换为秒
    return (idle / REDIS_LRU_CLOCK_RESOLUTION);
}
```

**LFU 算法实现：**
```c
// Redis 4.0+ 支持 LFU

struct redisObject {
    // ...
    unsigned lru:24;  // 低 16 位：LRU 时钟
                     // 高 8 位：访问次数对数
};

// 访问计数
void incrementKeyFrequency(robj* key) {
    // 访问次数 +1（使用对数计数器）
    uint8_t count = key->lru >> 8;
    
    // 访问次数衰减
    if (LFUTimeSinceLastUpdate() > LFUDecayTime) {
        count = (count * LFUDecayFactor) / 256;
    }
    
    count++;
    key->lru = (count << 8) | (key->lru & 0xFF);
}
```

**淘汰策略选择建议：**
```
场景选择：

1. 纯缓存，所有数据都重要
   → allkeys-random / allkeys-lru

2. 缓存热点数据，有明显冷热
   → allkeys-lru

3. 访问频率差异大
   → allkeys-lfu

4. 有过期时间的数据需要淘汰
   → volatile-lru / volatile-ttl

5. 数据不能丢失
   → noeviction（需要合理预估内存）
```

---

## 5. Redis 主从复制？

**题目：**
请详细说明 Redis 主从复制的原理和过程。

**答案：**
**主从复制架构：**
```
┌─────────────────────────────────────────────────────────────────┐
│                    Redis 主从复制架构                           │
│                                                              │
│                    ┌─────────┐                                │
│                    │ Master  │  读写操作                       │
│                    │ (写)    │                                │
│                    └───┬─────┘                                │
│                        │                                      │
│                        │ 复制命令流                            │
│                        ▼                                      │
│  ┌─────────────────────────────────────────────────────────┐  │
│  │  Replication Stream                                    │  │
│  │  PSYNC / REPLCONF / WAIT                              │  │
│  └─────────────────────────────────────────────────────────┘  │
│                        │                                      │
│         ┌──────────────┼──────────────┐                      │
│         ▼              ▼              ▼                      │
│    ┌─────────┐   ┌─────────┐   ┌─────────┐                  │
│    │ Slave1  │   │ Slave2  │   │ Slave3  │  只读操作         │
│    └─────────┘   └─────────┘   └─────────┘                  │
│                                                              │
└─────────────────────────────────────────────────────────────────┘
```

**复制过程：**
```
1. 建立连接
   ├── 从节点保存主节点信息
   ├── 建立 socket 连接
   └── 开启定时任务定时同步

2. 身份验证
   ├── 主从节点配置相同的 masterauth
   └── 验证通过后继续

3. 发送 PING
   ├── 从节点发送 PING
   ├── 主节点返回 PONG
   └── 检查连接状态

4. 权限验证
   ├── 主节点检查从节点的 ACL
   └── 验证通过后授权复制

5. 数据同步
   ├── 从节点发送 PSYNC 命令
   ├── 主节点执行 BGSAVE 生成 RDB
   ├── 主节点发送 RDB 文件给从节点
   ├── 主节点发送缓存的复制命令
   └── 从节点加载 RDB 数据

6. 命令传播
   ├── 主节点将写命令发送给所有从节点
   └── 从节点执行命令保持数据一致
```

**PSYNC 命令：**
```c
// PSYNC 语法
PSYNC <runid> <offset>

// runid：主节点运行 ID
// offset：从节点复制偏移量

// 两种同步方式：
// 1. 全量复制（Full Sync）
//    - 首次连接
//    - 主节点 runid 变化
//    - 从节点 offset 超出范围

// 2. 增量复制（Partial Sync）
//    - 主从连接中断后重连
//    - offset 在主节点的复制积压缓冲区中
```

**增量复制：**
```
┌─────────────────────────────────────────────────────────────┐
│                    增量复制原理                               │
│                                                              │
│  主节点维护：                                                  │
│  ┌─────────────────────────────────────────────────────┐    │
│  │               复制积压缓冲区（环形）                   │    │
│  │  ┌─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┐ │    │
│  │  │ CMD1│ CMD2│ CMD3│ CMD4│ CMD5│ CMD6│ CMD7│ CMD8│ │    │
│  │  └─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┘ │    │
│  │                       ▲                              │    │
│  │                       │ offset                       │    │
│  └─────────────────────────────────────────────────────┘    │
│                                                              │
│  从节点断开重连：                                              │
│  1. 从节点发送 PSYNC runid offset                             │
│  2. 主节点检查 offset 是否在缓冲区中                          │
│  3. 在缓冲区中：发送缺失的命令                                 │
│  4. 不在缓冲区中：全量复制                                     │
└─────────────────────────────────────────────────────────────┘
```

**复制积压缓冲区：**
```c
// 配置
repl-backlog-size 64mb    // 缓冲区大小
repl-backlog-ttl 3600     // 缓冲区保留时间
```

**WAIT 命令：**
```java
// 等待指定数量的从节点确认复制

// 使用 WAIT
jedis.set("key", "value");
jedis.wait(1, 1000);  // 等待1个从节点，1000ms超时
```

**复制优化：**
```bash
# 1. 调整复制缓冲区大小
repl-backlog-size 128mb

# 2. 开启无盘复制
repl-diskless-sync yes
repl-diskless-sync-delay 5

# 3. 限制从节点数量
min-slaves-to-write 3
min-slaves-max-lag 10

# 4. 开启从节点只读
slave-read-only yes
```
